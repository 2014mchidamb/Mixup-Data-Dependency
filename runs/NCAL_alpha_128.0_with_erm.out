The following model/training parameters were used for this run: 

batch_size =  128
mixup_alpha =  128.0
h_dim =  512
num_hidden =  1
lr =  0.001
epochs =  5000
num_runs =  10
-------------------------------------------------

Mixup model training loss results: 
-------------------------------------------------

Mixup average test error over 10 runs: 33.33%
-------------------------------------------------

Base model training loss results: 
-------------------------------------------------

Base average test error over 10 runs: 0.00%
-------------------------------------------------

Mixup Model Evaluations: 
[[9.9979037e-01 2.0963207e-04]
 [6.5027887e-01 3.4972116e-01]
 [9.9799299e-01 2.0069843e-03]]
