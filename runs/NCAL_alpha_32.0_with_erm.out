The following model/training parameters were used for this run: 

batch_size =  128
mixup_alpha =  32.0
h_dim =  512
num_hidden =  1
lr =  0.001
epochs =  5000
num_runs =  10
-------------------------------------------------

Mixup model training loss results: 
-------------------------------------------------

Mixup average test error over 10 runs: 33.33%
-------------------------------------------------

Base model training loss results: 
-------------------------------------------------

Base average test error over 10 runs: 0.00%
-------------------------------------------------

Mixup Model Evaluations: 
[[9.9960965e-01 3.9037288e-04]
 [6.0343349e-01 3.9656648e-01]
 [9.9677926e-01 3.2208532e-03]]
